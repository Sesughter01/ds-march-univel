{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4d10c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pymysql.cursors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d8d522ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_db( query:str ):\n",
    "    \n",
    "    \"\"\"\n",
    "        This function takes a query and then sends it to the database.\n",
    "    \"\"\"\n",
    "    connection = pymysql.connect(host='localhost',\n",
    "                                 user='root',\n",
    "                                 password='',\n",
    "                                 database='loan',\n",
    "                                 cursorclass=pymysql.cursors.DictCursor)\n",
    "    with connection:\n",
    "        with connection.cursor() as cursor:\n",
    "            cursor.execute(query)\n",
    "\n",
    "        connection.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6a1cd91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file()->dict:\n",
    "    \n",
    "    \"\"\"This function gets a file name(csv format), \n",
    "        reads it and returns the column names, \n",
    "        also the records and filename, in a dictionary\n",
    "    \"\"\"\n",
    "    \n",
    "    header = None # COLUMN NAMES\n",
    "    records = [] # CORRESPONDING TABLE RECORDS FROM CSV\n",
    "    \n",
    "    path = input(\"Please enter file name or path\\n:> \")\n",
    "    with open(path) as csv_file:\n",
    "        \n",
    "        csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "        line_count = 0\n",
    "        for row in csv_reader:\n",
    "\n",
    "            if line_count == 0:\n",
    "#                 print(f'\\t{row[1].ljust(15)} {row[3].ljust(25)} {row[5].ljust(15)}  {row[14].rjust(9)} {row[9].rjust(9)} \\n')\n",
    "                header = row # We assign the first row as the header.\n",
    "                line_count += 1\n",
    "            else:\n",
    "#                 print(f'\\t{row[1].ljust(15)} {row[3].ljust(25)} {row[5].ljust(15)}  {row[14].rjust(9)} {row[9].rjust(9)} \\n')\n",
    "                records.append(row) # Here we assign all the other rows to the records list.\n",
    "                line_count += 1\n",
    "        print(f'Processed {line_count} lines.')\n",
    "    \n",
    "    de_extensioned_filename = path.split(\".\")[0].replace(\" \", \"\").replace(\"-\", \"\")\n",
    "    return dict(colnames = header, records = records, filename = de_extensioned_filename)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e09e2f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter file name or path\n",
      ":> \n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_29572/2823337760.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprocess_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_29572/3635575010.py\u001b[0m in \u001b[0;36mprocess_file\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Please enter file name or path\\n:> \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcsv_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mcsv_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcsv_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: ''"
     ]
    }
   ],
   "source": [
    "process_file().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "540066de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_table_from_cols(colnames:list, use_name:str)->bool:\n",
    "    \n",
    "    \"\"\"\n",
    "        This function will allow you to pass in a list of column names, \n",
    "        and another string which is the name for the new table,\n",
    "        It will then create an sql query that would be used to create\n",
    "        corresponding sql table.\n",
    "        \n",
    "        returns boolean (True/False) if task is successful or not respectively.\n",
    "    \"\"\"\n",
    "    \n",
    "    sql_query = f\"CREATE TABLE {use_name} (main_id INT(4) PRIMARY KEY AUTO_INCREMENT NOT NULL\" # Creat base query which will be same accross all tables created.\n",
    "    \n",
    "    for colname in colnames:\n",
    "        \n",
    "        if colname == \"\": # Deal with column name that are empty\n",
    "            colname = \"unknown_col\"\n",
    "        \n",
    "        colname = colname.replace(\" \", \"\")\n",
    "        sql_query += f\", {str(colname).strip()} VARCHAR(30)\" # Table info for each column name.\n",
    "    \n",
    "    sql_query += \");\" # Add closing tokens to query\n",
    "    \n",
    "    print(sql_query)\n",
    "    write_to_db(sql_query)\n",
    "    print(sql_query)\n",
    "    \n",
    "    return True\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "735570fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter file name or path\n",
      ":> EGLC-CDD.csv\n",
      "Processed 13 lines.\n",
      "CREATE TABLE EGLCCDD (main_id INT(4) PRIMARY KEY AUTO_INCREMENT NOT NULL, Monthstarting VARCHAR(30), CDD3 VARCHAR(30), CDD25 VARCHAR(30), CDD2 VARCHAR(30), CDD15 VARCHAR(30), CDD1 VARCHAR(30));\n",
      "CREATE TABLE EGLCCDD (main_id INT(4) PRIMARY KEY AUTO_INCREMENT NOT NULL, Monthstarting VARCHAR(30), CDD3 VARCHAR(30), CDD25 VARCHAR(30), CDD2 VARCHAR(30), CDD15 VARCHAR(30), CDD1 VARCHAR(30));\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_data = process_file()\n",
    "col_names = file_data[\"colnames\"]\n",
    "records = file_data[\"records\"]\n",
    "use_name = file_data[\"filename\"]\n",
    "\n",
    "create_table_from_cols(col_names, use_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3447e96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
